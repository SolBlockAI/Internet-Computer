no-interrupt:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  interruptible: False
  script:
    - echo "This pipeline is not interruptible"

boundary-node-service-worker:
  extends:
    - .build-k8s
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_TAG =~ /^service-worker_v([0-9\.]+)$/'
    - if: '$CI_PARENT_PIPELINE_SOURCE == "trigger"'
  script:
    - |
      set -eExuo pipefail
      # shellcheck disable=SC1090
      source "$NVM_DIR/nvm.sh"

      (
        cd typescript/service-worker

        nvm use
        node --version
        npm --version

        npm ci

        # perform linting
        npm run lint
        npm run format:check

        # run unit tests
        npm test

        # run e2e tests
        ./e2e/e2e --add-dependencies --start --run-tests --stop

        # build service worker
        npm run build
        npm run build-dev

        # prepase release artifact
        npm pack
        mkdir artifacts
        mv dfinity-service-worker-*.tgz artifacts
        cd artifacts
        sha256sum dfinity-service-worker-*.tgz > SHA256SUMS
      )

      pip3 install --ignore-installed -r requirements.txt

      ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/find-build-id.sh)
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
        gitlab-ci/src/artifacts/rclone_upload.py --version="${GIT_REVISION}" "typescript/service-worker/artifacts" service-worker
  artifacts:
    reports:
      junit: typescript/service-worker/junit.xml
    paths:
      - typescript/service-worker/artifacts

.after-script-test:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/src/after_script/**/*
        - gitlab-ci/config/**/*
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  needs: [] # don't wait on other jobs
  script:
    - |
      set -eExuo pipefail

      cd "${CI_PROJECT_DIR}"

      shellcheck -x gitlab-ci/src/after_script/*.sh

      buildevents cmd "$CI_PIPELINE_ID" "$CI_JOB_ID" "$CI_JOB_NAME" -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

after-script-test-ic-build-legacy-image:
  extends:
    - .after-script-test
    - .build-k8s-legacy

after-script-test-ic-build-image:
  extends:
    - .after-script-test

bazel-build-fuzzers:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=fuzzing --build_tag_filters=libfuzzer"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-build-fuzzers-afl:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=afl"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

# check if this one works
bazel-build-fuzzers-weekly:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-fuzzers-to-clusterfuzz"'
  needs: [] # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      gcloud auth activate-service-account --key-file "${FUZZING_GCP_SERVICE_KEY}"
      ./build-all-fuzzers.sh --zip
      cd fuzzer_build
      gsutil -m cp libfuzzer_asan_linux_*.zip gs://ic_fuzzer_builds
      gsutil -m cp afl_asan_linux_*.zip gs://ic_fuzzer_builds

bazel-build-fuzzers-archives:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/config/main.yml
        - bin/build-all-fuzzers.sh
        - bazel/fuzz_testing.bzl
  needs: [] # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      ./build-all-fuzzers.sh --zip

.bazel-test-all:
  extends:
    - .build-k8s
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  tags:
    - dfinity-ic
    - bazel
  artifacts:
    when: always
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit: bazel-testlogs-gitlab/**/test.xml
  variables:
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
    BAZEL_COMMAND: "test"
    BAZEL_TARGETS: "//..."
  script:
    - ./gitlab-ci/src/bazel-ci/main.sh
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - !reference [after_script]

bazel-test-coverage:
  extends:
    - .bazel-test-all
    - .rules-post-master
  timeout: 80 minutes
  artifacts:
    expire_in: 14 days
    when: always
    paths:
      - cov_targets.txt
      - cov_report.dat
      - cov_html
  variables:
    BAZEL_COMMAND: "coverage"
    BAZEL_EXTRA_ARGS: "--combined_report=lcov"
  script:
    - |
      bazel query --universe_scope=//... \
          "kind(test, //rs/...) except kind(test, allrdeps(attr('tags', 'canister', //rs/...)))" > cov_targets.txt
      # shellcheck disable=SC2046,SC2086
      bazel ${BAZEL_STARTUP_ARGS} coverage ${BAZEL_CI_CONFIG} ${BAZEL_EXTRA_ARGS} \
          --combined_report=lcov $(<cov_targets.txt) || true
      cp bazel-out/_coverage/_coverage_report.dat cov_report.dat
      genhtml --output cov_html cov_report.dat
  after_script:
    - bazel clean --expunge

bazel-test-all:
  extends:
    - .bazel-test-all
  rules:
    - !reference [.bazel-test-all, rules]
    - if: '$CI_COMMIT_REF_PROTECTED == "true" && $CI_COMMIT_TAG =~ /^release-.+/'
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going $BAZEL_EXTRA_ARGS_RULES"
  timeout: 80 minutes

bazel-system-test-hotfix:
  extends:
    - .bazel-test-all
  #  If on the RC branch, whether "hotfix" is in the commit message or not,
  #  always perform automatic execution of the prod hotfix tests. This means that, hotfix
  #  tests are not only exercised on hotfix pipelines, but are also exercised on nightly
  #  release qualification pipelines to ensure the hotfix tests are always working.
  rules:
    - if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
      when: always
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "trigger"
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_MERGE_REQUEST_TITLE =~ /(\[rc\]|hotfix)/i'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_hotfix"

bazel-system-test-staging:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_staging"
  allow_failure: true

bazel-system-test-nightly:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly"
  timeout: 7h 30m

bazel-system-test-nightly-nns:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "nns-nightly"'
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly_nns"
  timeout: 60 minutes

bazel-config-check-all-rebuild:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=check"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-test-all-rebuild:
  extends:
    - .bazel-test-all
    - .rules-post-master
  variables:
    BAZEL_CI_CONFIG: "--config=ci"
    BAZEL_COMMAND: "build"
    BAZEL_EXTRA_ARGS: "--repository_cache= --disk_cache= --noremote_accept_cached --remote_instance_name=${CI_COMMIT_SHA} --@rules_rust//rust/settings:pipelined_compilation=True"
  timeout: 2h

bazel-test-macos:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  tags:
    - macos
  variables:
    BAZEL_STARTUP_ARGS: "--output_base /var/tmp/bazel-output//${CI_CONCURRENT_ID}"
    BAZEL_CI_CONFIG: "--config=ci --config macos_ci"
    BAZEL_COMMAND: "test"
    BAZEL_EXTRA_ARGS: "--test_tag_filters=test_macos"
    BAZEL_TARGETS: "//rs/... //publish/binaries/..."
  timeout: 90 minutes

.build-ic:
  extends:
    - .ic-build-image
  needs: []
  artifacts:
    reports:
      dotenv: nns.release.env
    paths:
      - bazel-build-log*.json*
  script:
    - |
      set -euo pipefail
      VERSION=$(git rev-parse HEAD)

      if [ "$CI_JOB_NAME" == "build-ic-release" ]; then
          # read NNS release version from git tree
          NNS_RELEASE_VERSION="$(jq -r '.subnets["tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe"]' testnet/mainnet_revisions.json)"
          # we pass nss version info to build-determinism-*-release jobs
          # we put it under /tmp due to git clean -ffdx within build-ic script
          echo "NNS_RELEASE_VERSION=$NNS_RELEASE_VERSION" > /tmp/nns.release.env

          # fetch and checkout this version
          git fetch origin "$NNS_RELEASE_VERSION"
          git checkout "$NNS_RELEASE_VERSION"
          # NOTE: ic/$VERSION in S3 will have artifacts
          #       for revision $NNS_RELEASE_VERSION !!!
      fi

      if [ "$CI_COMMIT_REF_PROTECTED" == "true" ]; then
          gitlab-ci/container/build-ic.sh -i -c -b
      else
          gitlab-ci/container/build-ic.sh -i -c -b --no-release
      fi

      # release binaries
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/release" "${CI_JOB_NAME}/release"
      # canister binaries
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/canisters" "${CI_JOB_NAME}/canisters"

      # guestos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/guestos" "${CI_JOB_NAME}/guest-os"
      # hostos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/hostos" "${CI_JOB_NAME}/host-os"
      # setupos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/setupos" "${CI_JOB_NAME}/setup-os"

      # clean up
      bazel clean --expunge

      # collect dotenv
      if [ -f /tmp/nns.release.env ]; then
          mv /tmp/nns.release.env .
      fi

# MR Pipeline
build-ic:
  extends:
    - .build-ic
    - .rules-master-pipeline-no-merge-train

# Scheduled Pipeline
build-ic-release:
  extends:
    - .build-ic
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-reproducibility"

lock-generate:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  needs: []
  tags:
    - dfinity-ic
    - bazel
  script:
    - |
      set -euo pipefail
      EXIT_STATUS=0

      # Check that cargo lock file needs to be regenerated.
      cargo check -p ic-sys

      # Check that bazel lock file needs to be regenerated.
      if ! bazel query @crate_index//:all ; then
        CARGO_BAZEL_REPIN=1 bazel sync --only=crate_index
        # Verify that it fixed.
        bazel query @crate_index//:all
        # Ensure pipeline will fail.
        EXIT_STATUS=1
      fi

      # The same for fuzzing build
      if ! SANITIZERS_ENABLED=1 bazel query @crate_index//:all ; then
        SANITIZERS_ENABLED=1 CARGO_BAZEL_REPIN=1 bazel sync --only=crate_index
        # Verify that it fixed.
        SANITIZERS_ENABLED=1 bazel query @crate_index//:all
        # Ensure pipeline will fail.
        EXIT_STATUS=1
      fi

      git add Cargo.lock Cargo.Bazel.*.lock
      git status
      if ! git diff --cached --quiet; then
        # If a merge request and not on a merge train then update the Cargo.lock file in the MR automatically.
        if [ "$CI_PIPELINE_SOURCE" = "merge_request_event" ]  && [ "$CI_MERGE_REQUEST_EVENT_TYPE" != "merge_train" ];then
          # There are some changes staged
          # Command might fail because the gitlab remote already exists from a previous run.
          git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
          git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
          git config --global user.email "infra+gitlab-automation@dfinity.org"
          git config --global user.name "IDX GitLab Automation"
          git commit -m"Automatically updated Cargo*.lock"
          git push origin HEAD:"${CI_COMMIT_REF_NAME}"
        fi
        EXIT_STATUS=1
      fi

      exit "${EXIT_STATUS}"

pre-commit:
  variables:
    # Set the pre-commit home to this directory so we can cache it
    # more easily.
    PRE_COMMIT_HOME: /cache/pre-commit/$CI_CONCURRENT_ID
  extends:
    - .build-k8s
    - .rules-master-pipeline-and-merge-request
  needs: [] # don't wait on other jobs
  script:
    - |
      set -eEuo pipefail

      rustup default stable

      pip3 install pre-commit

      # Make sure CI can pull from the private repo.
      if ! SKIP=bazel_rust_format_check,bazel_smoke pre-commit run -a --hook-stage=manual ; then
        echo "Pre-commit checks failed. Here is the diff of the changes:"
        git diff
        echo
        echo "You can fix the code locally by following these instructions in the same branch."
        echo
        echo "install pre-commit by following https://pre-commit.com/#installation:"
        echo "(brew|pip) install pre-commit"
        echo "pre-commit install"
        echo
        echo "Then, to fix the checks in this branch, run:"
        echo "pre-commit run --from-ref=\$(git merge-base HEAD master) --to-ref=HEAD"
        echo
        echo "And then commit the changes."
        exit 1
      fi

python-gitlab-ci-tests:
  extends:
    - .build-k8s
  rules:
    # this job breaks when not run against the default branch
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  needs: []
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
  artifacts:
    reports:
      junit: test_report.xml
    paths:
      - gitlab-ci/src/htmlcov
  script:
    - |
      set -xeuo pipefail
      pip3 install --ignore-installed -r requirements.txt
      cd gitlab-ci/src
      pytest -v -o junit_family=xunit1 --junitxml=../../test_report.xml --cov=. --cov-report=term --cov-report=term-missing --cov-report=html --cov-branch

cargo-clippy-linux:
  needs: [] # don't wait on other jobs
  extends:
    - .build-k8s
    - .rules-master-pipeline-and-merge-request
  variables:
    CARGO_BUILD_TARGET: "x86_64-unknown-linux-gnu"
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- \
          "$CI_PROJECT_DIR"/gitlab-ci/src/rust_lint/lint.sh

# Cargo is deprecated and will be replaced with Bazel.
# Until the migration is complete, run a simple check for build failures.
legacy-cargo-check:
  needs: [] # don't wait on other jobs
  extends:
    - .build-k8s
    - .rules-master-pipeline-and-merge-request
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- cargo check --tests --benches

cargo-build-release-linux:
  needs: [] # don't wait on other jobs
  extends:
    - .build-k8s
    - .rules-master-pipeline-and-merge-request
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- cargo build --release

benchmarks:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "rust-benchmarks"'
  needs: []
  artifacts:
    paths:
      - report
  timeout: 12h
  variables:
    BAZEL_COMMAND: "run"
    RUST_BACKTRACE: "full"
  tags:
    - rust-benchmarks
  script:
    - |
      set -eEuo pipefail

      TARGET_LIST=$(bazel query "attr(tags, 'rust_bench', ${TARGETS:-'//rs/...'})")
      for TARGET in $TARGET_LIST; do
          BAZEL_TARGETS="$TARGET"
          time ./gitlab-ci/src/bazel-ci/main.sh
      done
      find -L ./bazel-out -name 'benchmark.json'

      set -x
      while IFS= read -r bench_dir; do
        echo '{}' | jq -cMr \
          --slurpfile benchmark "$bench_dir/benchmark.json" \
          --slurpfile estimates "$bench_dir/estimates.json" \
          --arg system x86_64-linux \
          --arg timestamp "$(date --utc --iso-8601=seconds)" \
          --arg rev "$CI_COMMIT_SHA" \
          '.benchmark = $benchmark[] |
          .estimates = $estimates[] |
          .package = "replica-benchmarks" |
          .system = $system |
          .timestamp = $timestamp |
          .rev = $rev |
          .revCount = 1' \
          > report.json
        curl --fail --retry 2 -sS -o /dev/null -X POST -H 'Content-Type: application/json' --data @report.json \
          "https://elasticsearch.testnet.dfinity.network/ci-performance-test/_doc"
      done < <(find -L ./bazel-out -type d -path '*/new')
  parallel:
    matrix:
      - TARGETS: "//rs/crypto/..."
      - TARGETS: "//rs/state_manager/..."
      # IDX-2849
      #- TARGETS: "//rs/execution_environment/..."
      # IDX-2850
      #- TARGETS: "//... - //rs/crypto/... - //rs/execution_environment/..."

build-determinism:
  extends:
    - .build-k8s
    - .rules-master-pipeline-no-merge-train
  needs:
    - job: bazel-test-all
      artifacts: false
    - job: build-ic
      artifacts: false
  parallel:
    matrix:
      - PATH0: "release"
        PATH1: "build-ic/release"
      - PATH0: "canisters"
        PATH1: "build-ic/canisters"
      - PATH0: "guest-os/update-img"
        PATH1: "build-ic/guest-os"
      - PATH0: "host-os/update-img"
        PATH1: "build-ic/host-os"
      - PATH0: "setup-os/disk-img"
        PATH1: "build-ic/setup-os"
        SETUPOS_FLAG: "true"
  script:
    - |
      set -eExuo pipefail
      ./gitlab-ci/tools/build-diff.sh "$PATH0" "$PATH1"

build-determinism-release:
  extends:
    - .build-k8s
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-reproducibility"
  needs:
    - job: build-ic-release
  script:
    - |
      set -eExuo pipefail

      # TODO IDX-2757
      if [ "$CI_JOB_NAME" == "build-determinism-guest-update-img-release" ]; then
          OLD_PATH="$(git rev-parse HEAD)/build-ic-release/guest-os/update-img"
          if curl -sfSI --retry 2 "https://download.dfinity.systems/ic/$OLD_PATH/SHA256SUMS"; then
              PATH0="build-ic-release/guest-os/update-img"
          fi
      fi

      # what we've build in build-ic-release
      P0=$PATH0
      # what is live and available under $NNS_RELEASE_VERSION
      # NNS_RELEASE_VERSION is set in build-ic-release
      # shellcheck disable=SC2153
      P1="/${NNS_RELEASE_VERSION}/${PATH1}"

      ./gitlab-ci/tools/build-diff.sh "$P0" "$P1"
  parallel:
    matrix:
      - PATH0: "build-ic-release/release"
        PATH1: "release"
      - PATH0: "build-ic-release/canisters"
        PATH1: "canisters"
      - PATH0: "build-ic-release/guest-os"
        PATH1: "guest-os/update-img"

test-push-branch:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
      when: on_success
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      # The remote might already exist from a previous CI job run because GitLab re-uses the git repo.
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      git switch --force-create post-merge-tests-passed HEAD
      git push --force --set-upstream origin post-merge-tests-passed

cut-release-candidate:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "release-candidate-cut"'
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      # The remote might already exist from a previous CI job run because GitLab re-uses the git repo.
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      RC_BRANCH_NAME="rc--$(date '+%Y-%m-%d_%H-%M')"
      git switch --force-create "$RC_BRANCH_NAME" HEAD
      git push --force --set-upstream origin  "$RC_BRANCH_NAME"

release-boundary-node-service-worker:
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_TAG =~ /^service-worker_v([0-9\.]+)$/'
  needs: [boundary-node-service-worker]
  script:
    - |
      set -eExuo pipefail
      # shellcheck disable=SC1090
      source "$NVM_DIR/nvm.sh"
      nvm use 18
      node --version
      npm --version

      pip3 install --ignore-installed -r requirements.txt

      # download previously built artifact (during merge commit pipeline)
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/find-build-id.sh)
      "$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/rclone_download.py \
        --git-rev="${GIT_REVISION}" --remote-path="service-worker" \
        --out="typescript/service-worker/artifacts"

      (
        cd typescript/service-worker
        if [[ $CI_COMMIT_TAG =~ ^service-worker_v([0-9\.]+)$ ]]; then
          TAG_VERSION="${BASH_REMATCH[1]}"
        else
          echo "could not parse version from commit tag $CI_COMMIT_TAG"
          echo "check CI configuration, this job should not be run for malformed tags!"
          exit 1
        fi

        # verify the source version matches the tag
        PACKAGE_JSON_VERSION=$(< package.json jq '.version' -r)
        if [  "$PACKAGE_JSON_VERSION" != "$TAG_VERSION" ]; then
          echo "package.json version $PACKAGE_JSON_VERSION does not match tag version $TAG_VERSION"
          exit 1
        fi

        # extracts to folder package
        tar -xf "artifacts/dfinity-service-worker-$TAG_VERSION.tgz"

        # verify the prebuilt package version matches the tag
        PREBUILT_VERSION=$(< package/package.json jq '.version' -r)
        if [  "$PREBUILT_VERSION" != "$TAG_VERSION" ]; then
          echo "version $PREBUILT_VERSION contained in the prebuilt artifact does not match tag version $TAG_VERSION!"
          exit 1
        fi

        printf '%s\n' "//registry.npmjs.org/:_authToken=\${SW_NODE_AUTH_TOKEN}" "registry=https://registry.npmjs.org/" "always-auth=true" >> .npmrc
        npm publish "file:artifacts/dfinity-service-worker-$PACKAGE_JSON_VERSION.tgz" --access public
      )

# The actual logic for Honeycomb metrics export happens in the after script of these jobs.
# We export the Honeycomb API metrics in the after script, not in the job script. Because `buildevents build`
# must be run after `buildevents step` of the common after script.

notify-gitlab-success:
  extends:
    - .build-k8s
  rules:
    # Run on schedule pipelines as several Honeycomb alert rules rely on this.
    # TODO(IDX-2856): Disable when alerts will be send from superset.
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: on_success
    # Send a slack notification on rc--* pipeline succeeds.
    # Limit to "push" pipeline source so that GitLab doesn't send spurious alerts for manual or
    # scheduled pipelines that developers may create off the rc branch.
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
      when: on_success
  stage: finalize
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      pip3 install --ignore-installed -r requirements.txt

      # TODO(IDX-2856): remove this top level "if" when we will not need to run the job for schedule pipelines.
      if [[ "$CI_PIPELINE_SOURCE" == "push" ]] && [[ "$CI_COMMIT_REF_NAME" =~ ^rc--.* ]]; then
        if [[ "${CI_COMMIT_MESSAGE,,}" =~ hotfix ]]; then
            MESSAGE="✔ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. 🫑🫑🫑"
        else
            MESSAGE="✅ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. 🎉🎉🎉"
        fi
        cd "${CI_PROJECT_DIR}/gitlab-ci/src" || true
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" notify-slack -- notify_slack/notify_slack.py \
          "${MESSAGE}" --channel "release-management-alerts"
      fi

notify-gitlab-failure:
  extends:
    - .build-k8s
  rules:
    # Send a slack alert on rc--* pipeline failures.
    # Limit to "push" pipeline source so that GitLab doesn't send spurious alerts for manual or
    # scheduled pipelines that developers may create off the rc branch.
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
      when: on_failure
  stage: finalize
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      pip3 install --ignore-installed -r requirements.txt

      echo "notify gitlab failure"
      if [[ "${CI_COMMIT_MESSAGE,,}" =~ hotfix ]]; then
          MESSAGE="✘ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. 🌶🌶🌶"
      else
          MESSAGE="❌ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. 😭😭😭"
      fi
      cd "${CI_PROJECT_DIR}/gitlab-ci/src" || true
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" notify-slack -- notify_slack/notify_slack.py \
          "${MESSAGE}" --channel "release-management-alerts"

commit-lint:
  needs: []
  extends:
    - .build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      allow_failure: true
  script:
    - |
      set -eEuo pipefail

      git config --global user.email "idx@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      if ! cog verify  "${CI_MERGE_REQUEST_TITLE}"; then
        echo "Your commit message - '${CI_MERGE_REQUEST_TITLE}' does not respect conventional commit conventions" >&2
        echo "Please visit https://www.conventionalcommits.org/en/v1.0.0/ to learn more about conventional commit" >&2
        exit 1
      fi

zz-generated-gitlab:
  needs: []
  extends:
    - .ic-build-image
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/config/**/*
        - .gitlab-ci.yml
  script:
    - |
      set -eEuo pipefail

      output_file="gitlab-ci/config/zz-generated-gitlab-ci.yaml"

      curl -G "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/ci/lint" \
          -d "dry_run=true" \
          -d "include_jobs=true" \
          -d "ref=$CI_COMMIT_REF_NAME" \
          -H "Authorization: Bearer $GITLAB_API_TOKEN" | jq -r '.merged_yaml' >"$output_file"

      yq  'sort_keys(...)' -i "$output_file"

      if [ -n "$(git status --porcelain)" ]; then
          git config --global user.email "idx@dfinity.org"
          git config --global user.name "IDX GitLab Automation"
          git commit -am "Updating $output_file"
          git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git"
          git push --set-upstream origin HEAD:"$CI_COMMIT_REF_NAME"
      else
          echo "git working tree clean - no changes to be committed"
      fi

tnet-test:
  needs:
    - job: bazel-test-all
      artifacts: false
  tags:
    - dfinity-ic
    - ch
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      changes:
        - rs/tests/k8s/**/*
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      when: manual
      allow_failure: true
  variables:
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/tests/k8s:tnetctl"
  allow_failure: true
  script:
    - |
      # TODO: switch to bazel after chrono issue is handled
      #bazel build //rs/tests/k8s:tnetctl
      #TNETCTL=$(bazel cquery --output=files //rs/tests/k8s:tnetctl)
      cd rs/tests/k8s
      cargo build --release
      TNETCTL=target/release/tnetctl

      export KUBECONFIG=$KUBECONFIG_TNET_CREATOR
      export RUST_LOG=info
      export NAME="CI-$CI_JOB_ID"

      # Build a subnet with a "zero" version, unless our built images actually
      # contain a "real" version.
      use_zero_version="true"
      if [ "$CI_COMMIT_REF_PROTECTED" = "true" ]; then
          use_zero_version="false"
      fi
      if [[ "$CI_COMMIT_REF_NAME" =~ ^hotfix-.+-rc--.+ ]]; then
          use_zero_version="false"
      fi

      echo "Testing tnetctl on the following environment"
      kubectl config get-contexts

      ./$TNETCTL list
      N=$(./$TNETCTL list | grep 'CI-' -c) || true
      N_LIMIT=20
      if [ "$N" -gt "$N_LIMIT" ]; then
          echo "Seeing already $N_LIMIT CI-* testnets deployed."
          echo "They should have been deleted by GC. Investigate and purge them."
          exit 1
      fi

      if [ "${use_zero_version}" == "true" ]; then
        ./$TNETCTL create \
            --version "$CI_COMMIT_SHA" \
            --use-zero-version \
            --init \
            --nns 2 \
            --app 1 \
            -n "$NAME"
      else
        ./$TNETCTL create \
            --version "$CI_COMMIT_SHA" \
            --init \
            --nns 2 \
            --app 1 \
            -n "$NAME"
      fi

      TNET_OPERATOR=$(./$TNETCTL list | grep $NAME | awk '{ print $1 }')-operator
      kubectl -n tnets wait --timeout=120s --for=condition=PodScheduled pod/"$TNET_OPERATOR"
      sleep 30
      kubectl -n tnets logs -f "$TNET_OPERATOR" -c init &
      timeout 10m \
          bash -c "kubectl -n tnets logs -f $TNET_OPERATOR -c init | grep -q 'All NNS canisters have been set up'"
      kill "$(jobs -p)" || true
